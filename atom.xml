<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://heshiyingx.github.io</id>
    <title>烂笔头</title>
    <updated>2021-02-20T13:35:33.276Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://heshiyingx.github.io"/>
    <link rel="self" href="https://heshiyingx.github.io/atom.xml"/>
    <subtitle>温故而知新</subtitle>
    <logo>https://heshiyingx.github.io/images/avatar.png</logo>
    <icon>https://heshiyingx.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 烂笔头</rights>
    <entry>
        <title type="html"><![CDATA[JetBrains 开发IDE 2020.4 以下版本最新全家桶系列产品激活破解方法]]></title>
        <id>https://heshiyingx.github.io/post/jetbrains-kai-fa-ide-20204-yi-xia-ban-ben-zui-xin-quan-jia-tong-xi-lie-chan-pin-ji-huo-po-jie-fang-fa/</id>
        <link href="https://heshiyingx.github.io/post/jetbrains-kai-fa-ide-20204-yi-xia-ban-ben-zui-xin-quan-jia-tong-xi-lie-chan-pin-ji-huo-po-jie-fang-fa/">
        </link>
        <updated>2021-02-05T13:24:51.000Z</updated>
        <summary type="html"><![CDATA[<p><a href="https://www.macfz.com/a/Jetbrainscrack.html">转载于</a><br>
2020-11-26日更新通知，jetbrains-agent这个项目停止了！但现在zhile.io大佬提供了一个新的思路方法大家可以试下！感谢zhile.io大佬这么多年的辛苦工作，希望大家也能理解！</p>
]]></summary>
        <content type="html"><![CDATA[<p><a href="https://www.macfz.com/a/Jetbrainscrack.html">转载于</a><br>
2020-11-26日更新通知，jetbrains-agent这个项目停止了！但现在zhile.io大佬提供了一个新的思路方法大家可以试下！感谢zhile.io大佬这么多年的辛苦工作，希望大家也能理解！</p>
<!-- more -->
<h1 id="0x0-项目背景">0x0. 项目背景</h1>
<p>Jetbrains家的产品有一个很良心的地方，他会允许你试用30天（这个数字写死在代码里了）以评估是否你真的需要为它而付费。<br>
但很多时候会出现一种情况：IDE并不能按照我们实际的试用时间来计算。<br>
我举个例子：如果我们开始了试用，然后媳妇生孩子要你回去陪产！陪产时我们并无空闲对IDE试用评估，它依旧算试用时间。（只是举个例子，或许你并没有女朋友）<br>
发现了吗？你未能真的有30天来对它进行全面的试用评估，你甚至无法作出是否付费的决定。此时你会想要延长试用时间，然而Jetbrains并未提供相关功能，该怎么办？</p>
<p>事实上有一款插件可以实现这个功能，你或许可以用它来重置一下试用时间。但切记不要无休止的一直试用，这并不是这个插件的本意！</p>
<h1 id="0x1-如何安装">0x1. 如何安装</h1>
<ul>
<li>1). 插件市场安装：<br>
在Settings/Preferences... -&gt; Plugins 内手动添加第三方插件仓库地址：https://plugins.zhile.io<br>
搜索：IDE Eval Reset插件进行安装。如果搜索不到请注意是否做好了上一步？网络是否通畅？<br>
插件会提示安装成功。</li>
<li>2). 下载安装：<br>
<a href="https://www.macfz.com/a/IDEeval.html">点击这个链接</a>(v2.1.6)下载插件的zip包（macOS可能会自动解压，然后把zip包丢进回收站）<br>
通常可以直接把zip包拖进IDE的窗口来进行插件的安装。如果无法拖动安装，你可以在Settings/Preferences... -&gt; Plugins 里手动安装插件（Install Plugin From Disk...）<br>
插件会提示安装成功。</li>
</ul>
<h1 id="0x2-如何使用">0x2. 如何使用</h1>
<ul>
<li>一般来说，在IDE窗口切出去或切回来时（窗口失去/得到焦点）会触发事件，检测是否长时间（25天）没有重置，给通知让你选择。（初次安装因为无法获取上次重置时间，会直接给予提示）</li>
<li>也可以手动唤出插件的主界面：
<ul>
<li>如果IDE没有打开项目，在Welcome界面点击菜单：Get Help -&gt; Eval Reset</li>
<li>如果IDE打开了项目，点击菜单：Help -&gt; Eval Reset</li>
</ul>
</li>
<li>唤出的插件主界面中包含了一些显示信息，2个按钮，1个勾选项：
<ul>
<li>按钮：Reload 用来刷新界面上的显示信息。</li>
<li>按钮：Reset 点击会询问是否重置试用信息并重启IDE。选择Yes则执行重置操作并重启IDE生效，选择No则什么也不做。（此为手动重置方式）</li>
<li>勾选项：Auto reset before per restart 如果勾选了，则自勾选后每次重启/退出IDE时会自动重置试用信息，你无需做额外的事情。（此为自动重置方式）</li>
</ul>
</li>
</ul>
<h1 id="0x3-如何更新">0x3. 如何更新</h1>
<ul>
<li>1). 插件更新机制（推荐）：
<ul>
<li>IDE会自行检测其自身和所安装插件的更新并给予提示。如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新。</li>
<li>点击IDE的Check for Updates... 菜单手动检测IDE和所安装插件的更新。如果本插件有更新，你会收到提示看到更新日志，自行选择是否更新。</li>
<li>插件更新可能会需要重启IDE。</li>
</ul>
</li>
<li>2). 手动更新：
<ul>
<li>从本页面下载最新的插件zip包安装更新。参考本文：下载安装小节。</li>
<li>插件更新需要重启IDE。</li>
</ul>
</li>
</ul>
<h1 id="0x4-一些说明">0x4. 一些说明</h1>
<ul>
<li>本插件默认不会显示其主界面，如果你需要，参考本文：如何使用小节。</li>
<li>市场付费插件的试用信息也会一并重置。</li>
<li>对于某些付费插件（如: Iedis 2, MinBatis）来说，你可能需要去取掉javaagent配置（如果有）后重启IDE：
<ul>
<li>如果IDE没有打开项目，在Welcome界面点击菜单：Configure -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的行。</li>
<li>如果IDE打开了项目，点击菜单：Help -&gt; Edit Custom VM Options... -&gt; 移除 -javaagent: 开头的行。</li>
<li>重置需要重启IDE生效！</li>
<li>重置后并不弹出Licenses对话框让你选择输入License或试用，这和之前的重置脚本/插件不同（省去这烦人的一步）。</li>
<li>如果长达25天不曾有任何重置动作，IDE会有通知询问你是否进行重置。</li>
<li>如果勾选：Auto reset before per restart ，重置是静默无感知的。</li>
<li>简单来说：勾选了Auto reset before per restart则无需再管，一劳永逸。</li>
</ul>
</li>
</ul>
<h1 id="0x5-开源信息">0x5. 开源信息</h1>
<ul>
<li>插件是学习研究项目，源代码是开放的。源码仓库地址：<a href="https://gitee.com/pengzhile/ide-eval-resetter">Gitee</a>。</li>
<li>如果你有更好的想法，欢迎给我提Pull Request来共同研究完善。</li>
<li>插件源码使用：GPL-2.0开源协议发布。</li>
<li>插件使用PHP编写，毕竟PHP是世界上最好的编程语言！</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[01.环境安装]]></title>
        <id>https://heshiyingx.github.io/post/huan-jing-an-zhuang/</id>
        <link href="https://heshiyingx.github.io/post/huan-jing-an-zhuang/">
        </link>
        <updated>2020-12-10T15:40:03.000Z</updated>
        <summary type="html"><![CDATA[<p>基础阶段的环境搭建。虚拟环境的搭建以及基础阶段常用的包的安装。</p>
]]></summary>
        <content type="html"><![CDATA[<p>基础阶段的环境搭建。虚拟环境的搭建以及基础阶段常用的包的安装。</p>
<!-- more -->
<h1 id="1虚拟环境virtualenv安装">1.🏡虚拟环境virtualenv安装</h1>
<p>python 的虚拟环境可以为一个 python 项目提供独立的解释环境、依赖包等资源，既能够很好的隔离不同项目使用不同 python 版本带来的冲突，而且还能方便项目的发布。</p>
<p>virtualenv可用于创建独立的 Python 环境，它会创建一个包含项目所必须要的执行文件。</p>
<h2 id="11-安装virtualenv">1.1 安装virtualenv</h2>
<pre><code class="language-python">sudo pip3 install virtualenv
# 配置 pip 安装第三方库的镜像源地址
sudo pip install -i https://pypi.douban.com/simple virtualenv
# 查看版本
virtualenv --version
</code></pre>
<h2 id="12-virtualenv使用方法">1.2 virtualenv使用方法</h2>
<p>如下命令表示在当前目录下创建一个名叫 env 的目录（虚拟环境），该目录下包含了独立的 Python 运行程序,以及 pip副本用于安装其他的 packge</p>
<pre><code class="language-python"># 当前目录创建虚拟环境
virtualenv [虚拟环境名称]
# 创建 env 的时候可以选择 Python 解释器，例如：
virtualenv -p /usr/local/bin/python3 [虚拟环境名称]
</code></pre>
<p>默认情况下，虚拟环境会依赖系统环境中的 site packages，就是说系统中已经安装好的第三方 package 也会安装在虚拟环境中，如果不想依赖这些 package，那么可以加上参数 --no-site-packages 建立虚拟环境</p>
<pre><code class="language-python"># 创建的虚拟环境不包含系统环境中的site packages
virtualenv --no-site-packages [虚拟环境名称]
</code></pre>
<p><strong>启动虚拟环境</strong></p>
<pre><code class="language-python">cd  [虚拟环境名称]
source ./bin/activate
</code></pre>
<p><strong>退出虚拟环境</strong></p>
<pre><code class="language-python">deactivate
</code></pre>
<p><strong>在虚拟环境安装 Python packages</strong><br>
Virtualenv 附带有 pip 安装工具，因此需要安装的 packages 可以直接运行：</p>
<pre><code class="language-python">pip install [套件名称]
</code></pre>
<h2 id="13-virtualenvwrapper">1.3 Virtualenvwrapper</h2>
<p>Virtualenvwrapper 是一个虚拟环境管理工具，它能够管理创建的虚拟环境的位置，并能够方便地查看虚拟环境的名称以及切换到指定的虚拟环境。</p>
<p><strong>安装（确保virtualenv已经安装）</strong><br>
安装需要在非虚拟环境下进行</p>
<pre><code class="language-python">sudo pip install virtualenvwrapper
# 或者使用豆瓣源
sudo pip install -i https://pypi.douban.com/simple virtualenvwrapper
</code></pre>
<p><strong>查找virtualenvwrapper.sh</strong></p>
<pre><code class="language-python">which virtualenvwrapper.sh
</code></pre>
<blockquote>
<p>我的机器上的位置是：/Library/Frameworks/Python.framework/Versions/3.4/bin/virtualenvwrapper.sh</p>
</blockquote>
<p><strong>修改.bash_profile</strong><br>
打开/Users/用户名/.bash_profile ，在最后加入：</p>
<pre><code class="language-bash">export WORKON_HOME=$HOME/.virtualenvs
export VIRTUALENVWRAPPER_SCRIPT=/Library/Frameworks/Python.framework/Versions/3.4/bin/virtualenvwrapper.sh
export VIRTUALENVWRAPPER_PYTHON=/Library/Frameworks/Python.framework/Versions/3.4/bin/python3
export VIRTUALENVWRAPPER_VIRTUALENV=/Library/Frameworks/Python.framework/Versions/3.4/bin/virtualenv
export VIRTUALENVWRAPPER_VIRTUALENV_ARGS='--no-site-packages'
source /Library/Frameworks/Python.framework/Versions/3.4/bin/virtualenvwrapper.sh
</code></pre>
<h2 id="14-virtualenvwrapper的使用">1.4 Virtualenvwrapper的使用</h2>
<p><strong>创建虚拟机</strong></p>
<pre><code class="language-python">mkvirtualenv [虚拟环境名称]
# 当然也可以指定虚拟机的 python 版本
mkvirtualenv [虚拟环境名称] -p /usr/local/bin/python3 
</code></pre>
<p><strong>列出虚拟环境列表</strong></p>
<pre><code class="language-bash">workon 或者 lsvirtualenv
</code></pre>
<p><strong>启动/切换虚拟环境</strong></p>
<pre><code class="language-bash">workon [虚拟环境名称]
</code></pre>
<p><strong>删除虚拟环境</strong></p>
<pre><code class="language-bash">rmvirtualenv [虚拟环境名称]
</code></pre>
<p><strong>离开虚拟环境，和 virutalenv 一样的命令</strong></p>
<pre><code class="language-bash">deactivate
</code></pre>
<h1 id="2机器学习基础阶段的环境搭建">2.机器学习基础阶段的环境搭建</h1>
<p>整个机器学习基础阶段会用到Matplotlib、Numpy、Pandas等库，为了统一版本号在环境中使用，将所有的库及其版本放到了文件requirements.txt当中，然后统一安装</p>
<p><strong>新建一个用于人工智能环境的虚拟环境</strong></p>
<pre><code class="language-bash">mkvirtualenv ai_base
</code></pre>
<p>requirements.txt 的内容</p>
<pre><code class="language-bash">matplotlib==2.2.2
numpy==1.16.5
pandas==1.2.1
tables==3.6.1
jupyter==1.0.0
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[02.matplotlib的使用]]></title>
        <id>https://heshiyingx.github.io/post/02jupyter-notebook-de-shi-yong/</id>
        <link href="https://heshiyingx.github.io/post/02jupyter-notebook-de-shi-yong/">
        </link>
        <updated>2020-12-10T14:23:22.000Z</updated>
        <summary type="html"><![CDATA[<p>matplotlib.pyplot是使matplotlib像MATLAB一样工作的函数的集合。每个pyplot功能都会对图形进行一些更改：例如，创建图形，在图形中创建绘图区域，在绘图区域中绘制一些线条，用标签装饰绘图等。</p>
<p>在matplotlib.pyplot各种状态下，函数调用之间会保留在一起，以便跟踪当前图形和绘图区域之类的内容，并且绘图功能指向当前轴（请注意，此处和文档中大多数地方的“轴”是指到轴 的图形的部分 和不超过一个轴线的严格的数学术语）。</p>
]]></summary>
        <content type="html"><![CDATA[<p>matplotlib.pyplot是使matplotlib像MATLAB一样工作的函数的集合。每个pyplot功能都会对图形进行一些更改：例如，创建图形，在图形中创建绘图区域，在绘图区域中绘制一些线条，用标签装饰绘图等。</p>
<p>在matplotlib.pyplot各种状态下，函数调用之间会保留在一起，以便跟踪当前图形和绘图区域之类的内容，并且绘图功能指向当前轴（请注意，此处和文档中大多数地方的“轴”是指到轴 的图形的部分 和不超过一个轴线的严格的数学术语）。</p>
<!-- more -->
<h1 id="1中文显示问题解决">1.中文显示问题解决</h1>
<p>在Python脚本中动态设置matplotlibrc,这样也可以避免由于更改配置文件而造成的麻烦，具体代码如下：</p>
<pre><code class="language-python">from pylab import mpl
# 设置显示中文字体
mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]
</code></pre>
<p>有时候，字体更改后，会导致坐标轴中的部分字符无法正常显示，此时需要更改axes.unicode_minus参数：</p>
<pre><code class="language-python"># 设置正常显示符号
mpl.rcParams[&quot;axes.unicode_minus&quot;] = False
</code></pre>
<h1 id="2折线图">2.折线图</h1>
<pre><code class="language-python">import matplotlib.pyplot as plt
from pylab import mpl
# 设置显示中文字体
mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]
plt.plot([1, 2, 3, 4])
plt.ylabel('y轴名字')
plt.show()
</code></pre>
<p><img src="https://heshiyingx.github.io/post-images/1612511389835.png" alt="" loading="lazy"><br>
为什么x轴的范围是0-3，而y轴的范围是1-4。如果您向提供单个列表或数组 plot，则matplotlib假定它是y值的序列，并自动为您生成x值。由于python范围以0开头，因此默认的x向量的长度与y相同，但以0开头。因此x数据为 。[0, 1, 2, 3]</p>
<p>plot是一种多功能函数，它将接受任意数量的参数。例如，要绘制x与y的关系图，可以编写：</p>
<pre><code class="language-python">plt.plot([1, 2, 3, 4], [1, 4, 9, 16])
</code></pre>
<figure data-type="image" tabindex="1"><img src="https://heshiyingx.github.io/post-images/1612525683210.png" alt="" loading="lazy"></figure>
<h2 id="21-格式化绘图样式">2.1 格式化绘图样式</h2>
<p>对于每对x，y参数，都有一个可选的第三个参数，它是表示图的颜色和线条类型的格式字符串。格式字符串的字母和符号来自MATLAB，您将颜色字符串与线型字符串连接在一起。默认格式字符串是“ b-”，这是一条蓝色实线。例如，要用红色圆圈绘制以上内容</p>
<pre><code class="language-python">import matplotlib.pyplot as plt
from pylab import mpl
# 设置显示中文字体
mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]
plt.plot([1, 2, 3, 4], [1, 4, 9, 16],'ro')
plt.ylabel('y轴名字')
plt.axis([0, 6, 0, 20])
plt.show()
</code></pre>
<figure data-type="image" tabindex="2"><img src="https://heshiyingx.github.io/post-images/1612526412605.png" alt="" loading="lazy"></figure>
<h2 id="22-添加自定义xy的刻度">2.2 添加自定义x,y的刻度</h2>
<ul>
<li>plt.xticks(x, **kwargs)<br>
x:要显示的刻度值</li>
<li>plt.yticks(y, **kwargs)<br>
y:要显示的刻度值</li>
</ul>
<pre><code class="language-python">import matplotlib.pyplot as plt
import random
from pylab import mpl

# 设置显示中文字体
mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]

x = range(60)
y_shanghai = [random.uniform(10,27) for i in x]
plt.figure(figsize=(20,7),dpi=80)
plt.plot(x,y_shanghai)

# 构造x轴刻度标签
x_ticks_label = [&quot;11点{}分&quot;.format(i) for i in x]
# 构造y轴刻度
y_ticks = range(40)

# 修改x,y轴坐标的刻度显示
plt.xticks(x[::5], x_ticks_label[::5])
plt.yticks(y_ticks[::5])

plt.show()
</code></pre>
<figure data-type="image" tabindex="3"><img src="https://heshiyingx.github.io/post-images/1612526926570.png" alt="" loading="lazy"></figure>
<h2 id="23-添加网格显示">2.3 添加网格显示</h2>
<p>为了更加清楚地观察图形对应的值</p>
<pre><code class="language-python">plt.grid(True, linestyle='--', alpha=0.5)
</code></pre>
<figure data-type="image" tabindex="4"><img src="https://heshiyingx.github.io/post-images/1612529668398.png" alt="" loading="lazy"></figure>
<h2 id="24-添加描述信息">2.4 添加描述信息</h2>
<p>添加x轴、y轴描述信息及标题</p>
<blockquote>
<p>通过fontsize参数可以修改图像中字体的大小</p>
</blockquote>
<pre><code class="language-python">plt.xlabel(&quot;时间&quot;)
plt.ylabel(&quot;温度&quot;)
plt.title(&quot;中午11点0分到12点之间的温度变化图示&quot;, fontsize=20)
</code></pre>
<figure data-type="image" tabindex="5"><img src="https://heshiyingx.github.io/post-images/1612529749219.png" alt="" loading="lazy"></figure>
<h2 id="25-图像保存">2.5 图像保存</h2>
<pre><code class="language-python"># 保存图片到指定路径
plt.savefig(&quot;test.png&quot;)
</code></pre>
<p>注意：plt.show()会释放figure资源，如果在显示图像之后保存图片将只能保存空图片。</p>
<p><strong>完整代码</strong></p>
<pre><code class="language-python">import matplotlib.pyplot as plt
import random
from pylab import mpl

# 设置显示中文字体
mpl.rcParams[&quot;font.sans-serif&quot;] = [&quot;SimHei&quot;]

x = range(60)
y_shanghai = [random.uniform(10,27) for i in x]
plt.figure(figsize=(20,7),dpi=80)
plt.plot(x,y_shanghai)

# 构造x轴刻度标签
x_ticks_label = [&quot;11点{}分&quot;.format(i) for i in x]
# 构造y轴刻度
y_ticks = range(40)

# 修改x,y轴坐标的刻度显示
plt.xticks(x[::5], x_ticks_label[::5])
plt.yticks(y_ticks[::5])
plt.grid(True, linestyle='--', alpha=0.5)
plt.xlabel(&quot;时间&quot;)
plt.ylabel(&quot;温度&quot;)
plt.title(&quot;中午11点0分到12点之间的温度变化图示&quot;, fontsize=20)
plt.show()
</code></pre>
<h1 id="3-在一个坐标系中绘制多个图像">3 在一个坐标系中绘制多个图像</h1>
<h2 id="31-多次plot">3.1 多次plot</h2>
<p>需求：再添加一个城市的温度变化</p>
<p>收集到北京当天温度变化情况，温度在1度到3度。怎么去添加另一个在同一坐标系当中的不同图形，其实很简单只需要再次plot即可，但是需要区分线条，如下显示<br>
<img src="https://heshiyingx.github.io/post-images/1612530001960.png" alt="" loading="lazy"></p>
<pre><code class="language-python"># 增加北京的温度数据
y_beijing = [random.uniform(1, 3) for i in x]

# 绘制折线图
plt.plot(x, y_shanghai)
# 使用多次plot可以画多个折线
plt.plot(x, y_beijing, color='r', linestyle='--')
</code></pre>
<p>我们仔细观察，用到了两个新的地方，一个是对于不同的折线展示效果，一个是添加图例。</p>
<h2 id="32-设置图形风格">3.2 设置图形风格</h2>
<table>
<thead>
<tr>
<th>颜色字符</th>
<th>风格字符</th>
</tr>
</thead>
<tbody>
<tr>
<td>r 红色</td>
<td>- 实线</td>
</tr>
<tr>
<td>g 绿色</td>
<td>-- 虚线</td>
</tr>
<tr>
<td>b 蓝色</td>
<td>-. 点划线</td>
</tr>
<tr>
<td>w 白色</td>
<td>: 点虚线</td>
</tr>
<tr>
<td>c 青色</td>
<td>'' 留空、空格</td>
</tr>
<tr>
<td>m 洋红</td>
<td></td>
</tr>
</tbody>
</table>
<h2 id="33-显示图例">3.3 显示图例</h2>
<p>注意：如果只在plt.plot()中设置label还不能最终显示出图例，还需要通过plt.legend()将图例显示出来。</p>
<pre><code class="language-python"># 绘制折线图
plt.plot(x, y_shanghai, label=&quot;上海&quot;)
# 使用多次plot可以画多个折线
plt.plot(x, y_beijing, color='r', linestyle='--', label=&quot;北京&quot;)

# 显示图例
plt.legend(loc=&quot;best&quot;)
</code></pre>
<table>
<thead>
<tr>
<th>Location String</th>
<th>Location Code</th>
</tr>
</thead>
<tbody>
<tr>
<td>'best'</td>
<td>0</td>
</tr>
<tr>
<td>'upper right'</td>
<td>1</td>
</tr>
<tr>
<td>'upper left'</td>
<td>2</td>
</tr>
<tr>
<td>'lower left'</td>
<td>3</td>
</tr>
<tr>
<td>'lower right'</td>
<td>4</td>
</tr>
<tr>
<td>'right'</td>
<td>5</td>
</tr>
<tr>
<td>'center left'</td>
<td>6</td>
</tr>
<tr>
<td>'center right'</td>
<td>7</td>
</tr>
<tr>
<td>'lower center'</td>
<td>8</td>
</tr>
<tr>
<td>'upper center'</td>
<td>9</td>
</tr>
<tr>
<td>'center'</td>
<td>10</td>
</tr>
</tbody>
</table>
<p><strong>完整代码</strong></p>
<pre><code class="language-python"># 0.准备数据
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]
y_beijing = [random.uniform(1,3) for i in x]

# 1.创建画布
plt.figure(figsize=(20, 8), dpi=100)

# 2.绘制图像
plt.plot(x, y_shanghai, label=&quot;上海&quot;)
plt.plot(x, y_beijing, color=&quot;r&quot;, linestyle=&quot;--&quot;, label=&quot;北京&quot;)

# 2.1 添加x,y轴刻度
# 构造x,y轴刻度标签
x_ticks_label = [&quot;11点{}分&quot;.format(i) for i in x]
y_ticks = range(40)

# 刻度显示
plt.xticks(x[::5], x_ticks_label[::5])
plt.yticks(y_ticks[::5])

# 2.2 添加网格显示
plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)

# 2.3 添加描述信息
plt.xlabel(&quot;时间&quot;)
plt.ylabel(&quot;温度&quot;)
plt.title(&quot;中午11点--12点某城市温度变化图&quot;, fontsize=20)

# 2.4 图像保存
plt.savefig(&quot;./test.png&quot;)

# 2.5 添加图例
plt.legend(loc=0)

# 3.图像显示
plt.show()
</code></pre>
<h1 id="4-多个坐标系显示-pltsubplots面向对象的画图方法">4 多个坐标系显示— plt.subplots(面向对象的画图方法)</h1>
<p>如果我们想要将上海和北京的天气图显示在同一个图的不同坐标系当中，效果如下：<br>
<img src="https://heshiyingx.github.io/post-images/1612530885925.png" alt="" loading="lazy"><br>
可以通过subplots函数实现(旧的版本中有subplot，使用起来不方便)，推荐subplots函数<br>
**matplotlib.pyplot.subplots(nrows=1, ncols=1, <strong>fig_kw) 创建一个带有多个axes(坐标系/绘图区)的图</strong></p>
<pre><code class="language-python">Parameters:    

nrows, ncols : 设置有几行几列坐标系
    int, optional, default: 1, Number of rows/columns of the subplot grid.

Returns:    
fig : 图对象
axes : 返回相应数量的坐标系

设置标题等方法不同：
    set_xticks
    set_yticks
    set_xlabel
    set_ylabel
</code></pre>
<p>关于axes子坐标系的更多方法：参考https://matplotlib.org/api/axes_api.html#matplotlib.axes.Axes</p>
<p>注意：plt.函数名()相当于面向过程的画图方法，axes.set_方法名()相当于面向对象的画图方法。</p>
<p><strong>完整代码</strong></p>
<pre><code class="language-python"># 0.准备数据
x = range(60)
y_shanghai = [random.uniform(15, 18) for i in x]
y_beijing = [random.uniform(1, 5) for i in x]

# 1.创建画布
# plt.figure(figsize=(20, 8), dpi=100)
fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(20, 8), dpi=100)


# 2.绘制图像
# plt.plot(x, y_shanghai, label=&quot;上海&quot;)
# plt.plot(x, y_beijing, color=&quot;r&quot;, linestyle=&quot;--&quot;, label=&quot;北京&quot;)
axes[0].plot(x, y_shanghai, label=&quot;上海&quot;)
axes[1].plot(x, y_beijing, color=&quot;r&quot;, linestyle=&quot;--&quot;, label=&quot;北京&quot;)

# 2.1 添加x,y轴刻度
# 构造x,y轴刻度标签
x_ticks_label = [&quot;11点{}分&quot;.format(i) for i in x]
y_ticks = range(40)

# 刻度显示
# plt.xticks(x[::5], x_ticks_label[::5])
# plt.yticks(y_ticks[::5])
axes[0].set_xticks(x[::5])
axes[0].set_yticks(y_ticks[::5])
axes[0].set_xticklabels(x_ticks_label[::5])
axes[1].set_xticks(x[::5])
axes[1].set_yticks(y_ticks[::5])
axes[1].set_xticklabels(x_ticks_label[::5])

# 2.2 添加网格显示
# plt.grid(True, linestyle=&quot;--&quot;, alpha=0.5)
axes[0].grid(True, linestyle=&quot;--&quot;, alpha=0.5)
axes[1].grid(True, linestyle=&quot;--&quot;, alpha=0.5)

# 2.3 添加描述信息
# plt.xlabel(&quot;时间&quot;)
# plt.ylabel(&quot;温度&quot;)
# plt.title(&quot;中午11点--12点某城市温度变化图&quot;, fontsize=20)
axes[0].set_xlabel(&quot;时间&quot;)
axes[0].set_ylabel(&quot;温度&quot;)
axes[0].set_title(&quot;中午11点--12点某城市温度变化图&quot;, fontsize=20)
axes[1].set_xlabel(&quot;时间&quot;)
axes[1].set_ylabel(&quot;温度&quot;)
axes[1].set_title(&quot;中午11点--12点某城市温度变化图&quot;, fontsize=20)

# # 2.4 图像保存
plt.savefig(&quot;./test.png&quot;)

# # 2.5 添加图例
# plt.legend(loc=0)
axes[0].legend(loc=0)
axes[1].legend(loc=0)


# 3.图像显示
plt.show()
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[rocketmq1]]></title>
        <id>https://heshiyingx.github.io/post/rocketmq1/</id>
        <link href="https://heshiyingx.github.io/post/rocketmq1/">
        </link>
        <updated>2018-05-09T10:29:23.000Z</updated>
        <content type="html"><![CDATA[<h1 id="专业术语">专业术语</h1>
<ul>
<li>
<p>Producer<br>
消息生产者，负责产生消息，一般由业务系统负责产生消息。</p>
</li>
<li>
<p>Consumer<br>
消息消费者，负责消费消息，一般是后台系统负责异步消费。</p>
</li>
<li>
<p>PushConsumer<br>
Consumer 的一种，应用通常向 Consumer 对象注册一个 Listener 接口，一旦收到消息，Consumer对象立刻回调 Listener 接口方法。</p>
</li>
<li>
<p>Pull Consumer<br>
Consumer 的一种，应用通常主劢调用 Consumer 的拉消息方法从 Broker 拉消息，主动权由应用控制。</p>
</li>
<li>
<p>Producer Group<br>
一类 Producer 的集合名称，这类Producer通常发送一类消息，且发送逻辑一致。</p>
</li>
<li>
<p>Consumer Group<br>
一类 Consumer 的集合名称，返类 Consumer 通常消费一类消息，且消费逻辑一致。</p>
</li>
<li>
<p>Broker<br>
消息中转角色，负责存储消息，转发消息，一般也称为 Server。在 JMS 规范中称为 Provider。</p>
</li>
<li>
<p>Message Queue<br>
在 RocketMQ 中，所有消息队列都是持久化，长度无限的数据结构，所谓长度无限是指队列中的每个存储<br>
单元都是定长，访问其中的存储单元使用 Offset 来访问，offset 为 java long 类型，64 位，理论上在 100 年内不会溢出，所以认为是长度无限，另外队列中只保存最近几天的数据，之前的数据会按照过期时间来删除。<br>
也可以认为 Message Queue 是一个长度无限的数组，offset 就是下标。</p>
</li>
<li>
<p>广播消费<br>
一条消息被多个Consumer消费，即使这些Consumer属于同一个Consumer Group，消息也会被 Consumer Group 中的每个Consumer都消费一次，广播消费中的Consumer Group概念可以认为在消息划分方面无意义。<br>
在 CORBA Notification 规范中，消费方式都属于广播消费。<br>
在 JMS 规范中，相当于 JMS publish/subscribe model</p>
</li>
<li>
<p>集群消费<br>
一个 Consumer Group 中的 Consumer 实例平均分摊消费消息。例如某个 Topic 有 9 条消息，其中一个 Consumer Group 有 3 个实例(可能是 3个迕程，或者3台机器)，那么每个实例只消费其中的 3 条消息。 在 CORBA Notification 规范中，无此消费方式。<br>
在 JMS 规范中，JMS point-to-point model 不与之类似，但是 RocketMQ 的集群消费功能大概等于 PTP 模型。 因为RocketMQ 单个 Consumer Group 内的消费者类似于PTP，但是一个 Topic/Queue 可以被多个Consumer Group消费。</p>
</li>
<li>
<p>顺序消息<br>
消费消息的顺序要同发送消息的顺序一致，在RocketMQ 中，主要指的是局部顺序，即一类消息为满足顺 序性，必须 Producer 单线程顺序发送，且发送到同一个队列，返样 Consumer 就可以挄照 Producer发送的顺序去消费消息。</p>
</li>
<li>
<p>普通顺序消息<br>
顺序消息的一种，正常情况下可以保证完全的顺序消息，但是一旦发生通信异常，Broker重启，由于队列 总数发生发化，哈希取模后定位的队列会发化，产生短暂的消息顺序不一致。 如果业务能容忍在集群异常情冴(如某个 Broker 宕机戒者重启)下，消息短暂的乱序，使用普通顺序方 式比较合适。</p>
</li>
<li>
<p>严格顺序消息<br>
顺序消息的一种，无论正常异常情冴都能保证顺序，但是牺牲了分布式 Failover特性，即Broker集群中只要有一台机器不可用，则整个集群都不可用，服务可用性大大降低。 如果服务器部署为同步双写模式，此缺陷可通过备机自动切换为主避免，不过仍然会存在几分钟的服务不可用。(依赖同步双写，主备自动切换，自动切换功能目前还未实现)<br>
目前已知的应用只有数据库 binlog 同步强依赖严格顺序消息，其他应用绝大部分都可以容忍短暂乱序，推<br>
荐使用普通的顺序消息。</p>
</li>
</ul>
<h1 id="1rocketmq环境搭建">1.RocketMQ环境搭建</h1>
<h1 id="2rocketmq控制台部署与使用">2.RocketMQ控制台部署与使用</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[01.原来 8 张图，就可以搞懂「零拷贝」了]]></title>
        <id>https://heshiyingx.github.io/post/yuan-lai-8-zhang-tu-jiu-ke-yi-gao-dong-ling-kao-bei-liao/</id>
        <link href="https://heshiyingx.github.io/post/yuan-lai-8-zhang-tu-jiu-ke-yi-gao-dong-ling-kao-bei-liao/">
        </link>
        <updated>2018-05-03T11:20:04.000Z</updated>
        <content type="html"><![CDATA[<p><a href="https://www.cnblogs.com/xiaolincoding/p/13719610.html">转自小林coding</a></p>
<h1 id="前言">前言</h1>
<p>磁盘可以说是计算机系统最慢的硬件之一，读写速度相差内存 10 倍以上，所以针对优化磁盘的技术非常的多，比如零拷贝、直接 I/O、异步 I/O 等等，这些优化的目的就是为了提高系统的吞吐量，另外操作系统内核中的磁盘高速缓存区，可以有效的减少磁盘的访问次数。</p>
<p>这次，我们就以「文件传输」作为切入点，来分析 I/O 工作方式，以及如何优化传输文件的性能。<br>
<img src="https://heshiyingx.github.io/post-images/1613820135078.png" alt="" loading="lazy"></p>
<h1 id="为什么要有-dmadirect-memory-access-技术">为什么要有 DMA(Direct Memory Access) 技术?</h1>
<p>在没有 DMA 技术前，I/O 的过程是这样的：</p>
<ul>
<li>CPU 发出对应的指令给磁盘控制器，然后返回；</li>
<li>磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断；</li>
<li>CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。</li>
</ul>
<p>为了方便你理解，我画了一副图：<br>
<img src="https://heshiyingx.github.io/post-images/1613820229517.png" alt="" loading="lazy"><br>
可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。</p>
<p>简单的搬运几个字符数据那没问题，但是如果我们用千兆网卡或者硬盘传输大量数据的时候，都用 CPU 来搬运的话，肯定忙不过来。</p>
<p>计算机科学家们发现了事情的严重性后，于是就发明了 DMA 技术，也就是直接内存访问（Direct Memory Access） 技术。</p>
<p>什么是 DMA 技术？简单理解就是，<font color='blue'>在进行 I/O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。</font></p>
<p>那使用 DMA 控制器进行数据传输的过程究竟是什么样的呢？下面我们来具体看看。<br>
<img src="https://heshiyingx.github.io/post-images/1613820330110.png" alt="" loading="lazy"></p>
<p>具体过程：</p>
<ul>
<li>用户进程调用 read 方法，向操作系统发出 I/O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；</li>
<li>操作系统收到请求后，进一步将 I/O 请求发送 DMA，然后让 CPU 执行其他任务；</li>
<li>DMA 进一步将 I/O 请求发送给磁盘；</li>
<li>磁盘收到 DMA 的 I/O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；</li>
<li><font color='blue'>DMA收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务；</font></li>
<li>当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；</li>
<li>CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；</li>
</ul>
<p>可以看到， 整个数据传输的过程，CPU 不再参与数据搬运的工作，而是全程由 DMA 完成，但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。</p>
<p>早期 DMA 只存在在主板上，如今由于 I/O 设备越来越多，数据传输的需求也不尽相同，所以每个 I/O 设备里面都有自己的 DMA 控制器。</p>
<h1 id="传统的文件传输有多糟糕">传统的文件传输有多糟糕？</h1>
<p>如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。</p>
<p>传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。</p>
<p>代码通常如下，一般会需要两个系统调用：</p>
<pre><code class="language-c">read(file, tmp_buf, len);
write(socket, tmp_buf, len);
</code></pre>
<p>代码很简单，虽然就两行代码，但是这里面发生了不少的事情。<br>
<img src="https://heshiyingx.github.io/post-images/1613820538297.png" alt="" loading="lazy"></p>
<p>首先，期间共<font color='blue'>发生了 4 次用户态与内核态的上下文切换</font>，因为发生了两次系统调用，一次是 <font color='red'>read() </font>，一次是<font color='red'> write()</font>，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。</p>
<p>上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。</p>
<p>其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：</p>
<ul>
<li>第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。</li>
<li>第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。</li>
<li>第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。</li>
<li>第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。</li>
</ul>
<p>我们回过头看这个文件传输的过程，我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。</p>
<p>这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。</p>
<p>所以，<font color='blue'>要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。</font></p>
<h1 id="如何优化文件传输的性能">如何优化文件传输的性能？</h1>
<p><strong>先来看看，如何减少「用户态与内核态的上下文切换」的次数呢？</strong><br>
读取磁盘数据的时候，之所以要发生上下文切换，这是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候，就需要使用操作系统提供的系统调用函数。</p>
<p>而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。</p>
<p>所以，<font color='blue'>要想减少上下文切换到次数，就要减少系统调用的次数。</font></p>
<p><strong>再来看看，如何减少「数据拷贝」的次数？</strong><br>
在前面我们知道了，传统的文件传输方式会历经 4 次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。</p>
<p>因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此<font color='blue'>用户的缓冲区是没有必要存在的。</font></p>
<h1 id="如何实现零拷贝">如何实现零拷贝?</h1>
<p>零拷贝技术实现的方式通常有 2 种：</p>
<ul>
<li>mmap + write</li>
<li>sendfile<br>
下面就谈一谈，它们是如何减少「上下文切换」和「数据拷贝」的次数。</li>
</ul>
<h2 id="mmap-write">mmap + write</h2>
<p>在前面我们知道，<font color='red'>read()</font> 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 <font color='red'>mmap() </font>mmap() 替换 <font color='red'>read()</font>系统调用函数。</p>
<pre><code class="language-c">buf = mmap(file, len);
write(sockfd, buf, len);
</code></pre>
<p>mmap() 系统调用函数会直接把内核缓冲区里的数据<font color='red'>「映射」 </font>到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。<br>
<img src="https://heshiyingx.github.io/post-images/1613826695085.png" alt="" loading="lazy"></p>
<p>具体过程如下：</p>
<ul>
<li>应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；</li>
<li>应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li>
<li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。<br>
我们可以得知，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。</li>
</ul>
<p>但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。</p>
<h2 id="sendfile">sendfile</h2>
<p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p>
<p>首先，它可以替代前面的 <font color='red'>read() </font>和<font color='red'> write()</font>这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。</p>
<p>其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：<br>
<img src="https://heshiyingx.github.io/post-images/1613826838060.png" alt="" loading="lazy"></p>
<p>但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。</p>
<pre><code class="language-bash">$ ethtool -k eth0 | grep scatter-gather
scatter-gather: on
</code></pre>
<p>于是，从 Linux 内核 2.4 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， sendfile() 系统调用的过程发生了点变化，具体过程如下：</p>
<ul>
<li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li>
<li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；</li>
</ul>
<p>所以，这个过程之中，只进行了 2 次数据拷贝，如下图：<br>
<img src="https://heshiyingx.github.io/post-images/1613826964074.png" alt="" loading="lazy"><br>
这就是所谓的<font color='blue'>零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</font></p>
<p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<font color='blue'>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</font></p>
<p>所以，总体来看，<font color='blue'>零拷贝技术可以把文件传输的性能提高至少一倍以上。</font></p>
<h1 id="使用零拷贝技术的项目">使用零拷贝技术的项目</h1>
<p>事实上，Kafka 这个开源项目，就利用了「零拷贝」技术，从而大幅提升了 I/O 的吞吐率，这也是 Kafka 在处理海量数据为什么这么快的原因之一。</p>
<p>如果你追溯 Kafka 文件传输的代码，你会发现，最终它调用了 Java NIO 库里的 <font color='red'>transferTo</font> 方法：</p>
<pre><code class="language-java">@Overridepublic 
long transferFrom(FileChannel fileChannel, long position, long count) throws IOException { 
    return fileChannel.transferTo(position, count, socketChannel);
}
</code></pre>
<p>如果 Linux 系统支持 <font color='red'>sendfile()</font> 系统调用，那么 <font color='red'>transferTo() </font>实际上最后就会使用到 <font color='red'>sendfile()</font> 系统调用函数。</p>
<p>曾经有大佬专门写过程序测试过，在同样的硬件条件下，传统文件传输和零拷拷贝文件传输的性能差异，你可以看到下面这张测试数据图，使用了零拷贝能够缩短 65% 的时间，大幅度提升了机器传输数据的吞吐量。<br>
<img src="https://heshiyingx.github.io/post-images/1613827316939.png" alt="" loading="lazy"><br>
数据来源于：https://developer.ibm.com/articles/j-zerocopy/</p>
<p>另外，Nginx 也支持零拷贝技术，一般默认是开启零拷贝技术，这样有利于提高文件传输的效率，是否开启零拷贝技术的配置如下：</p>
<pre><code class="language-nginx">http {
...
    sendfile on
...
}
</code></pre>
<p>sendfile 配置的具体意思:</p>
<ul>
<li>设置为 on 表示，使用零拷贝技术来传输文件：sendfile ，这样只需要 2 次上下文切换，和 2 次数据拷贝。</li>
<li>设置为 off 表示，使用传统的文件传输技术：read + write，这时就需要 4 次上下文切换，和 4 次数据拷贝。</li>
</ul>
<p>当然，要使用 sendfile，Linux 内核版本必须要 2.1 以上的版本。</p>
<h1 id="pagecache-有什么作用">PageCache 有什么作用？</h1>
<p>回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是<font color='red'>磁盘高速缓存（PageCache）</font>。</p>
<p>由于零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能，我们接下来看看 PageCache 是如何做到这一点的。</p>
<p>读写磁盘相比读写内存的速度慢太多了，所以我们应该想办法把「读写磁盘」替换成「读写内存」。于是，我们会通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。</p>
<p>但是，内存空间远比磁盘要小，内存注定只能拷贝磁盘里的一小部分数据。</p>
<p>那问题来了，选择哪些磁盘数据拷贝到内存呢？</p>
<p>我们都知道程序运行的时候，具有「局部性」，所以通常，刚被访问的数据在短时间内再次被访问的概率很高，于是我们可以用<font color='red'>PageCache 来缓存最近被访问的数据</font> ，当空间不足时淘汰最久未被访问的缓存。</p>
<p>所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。</p>
<p>还有一点，读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，<font color='red'>PageCache 使用了「预读功能」</font> 。</p>
<p>比如，假设 read 方法每次只会读 32 KB 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。</p>
<p>所以，PageCache 的优点主要是两个：</p>
<ul>
<li>缓存最近被访问的数据；</li>
<li>预读功能；</li>
</ul>
<p>这两个做法，将大大提高读写磁盘的性能。</p>
<p><font color='blue'>但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能</font></p>
<p>这是因为如果你有很多 GB 级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。</p>
<p>另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：</p>
<ul>
<li>PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；</li>
<li>PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；</li>
</ul>
<p>所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。</p>
<h1 id="大文件传输用什么方式实现">大文件传输用什么方式实现？</h1>
<p>那针对大文件的传输，我们应该使用什么方式呢？</p>
<p>我们先来看看最初的例子，当调用 read 方法读取文件时，进程实际上会阻塞在 read 方法调用，因为要等待磁盘数据的返回，如下图：<br>
<img src="https://heshiyingx.github.io/post-images/1613827781619.png" alt="" loading="lazy"></p>
<p>具体过程：</p>
<ul>
<li>当调用 read 方法时，会阻塞着，此时内核会向磁盘发起 I/O 请求，磁盘收到请求后，便会寻址，当磁盘数据准备好后，就会向内核发起 I/O 中断，告知内核磁盘数据已经准备好；</li>
<li>内核收到 I/O 中断后，就将数据从磁盘控制器缓冲区拷贝到 PageCache 里；</li>
<li>最后，内核再把 PageCache 中的数据拷贝到用户缓冲区，于是 read 调用就正常返回了。</li>
</ul>
<p>对于阻塞的问题，可以用异步 I/O 来解决，它工作方式如下图：<br>
<img src="https://heshiyingx.github.io/post-images/1613827820166.png" alt="" loading="lazy"><br>
它把读操作分为两部分：</p>
<ul>
<li>前半部分，内核向磁盘发起读请求，但是可以不等待数据就位就可以返回，于是进程此时可以处理其他任务；</li>
<li>后半部分，当内核将磁盘中的数据拷贝到进程缓冲区后，进程将接收到内核的通知，再去处理数据；</li>
</ul>
<p>而且，我们可以发现，异步 I/O 并没有涉及到 PageCache，所以使用异步 I/O 就意味着要绕开 PageCache。</p>
<p>绕开 PageCache 的 I/O 叫直接 I/O，使用 PageCache 的 I/O 则叫缓存 I/O。通常，对于磁盘，异步 I/O 只支持直接 I/O。</p>
<p>前面也提到，大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache。</p>
<p>于是，<font color='blue'>在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I/O + 直接 I/O」来替代零拷贝技术。</font></p>
<p>直接 I/O 应用场景常见的两种：</p>
<ul>
<li>应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I/O，默认是不开启；</li>
<li>传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I/O。</li>
</ul>
<p>另外，由于直接 I/O 绕过了 PageCache，就无法享受内核的这两点的优化：</p>
<ul>
<li>内核的 I/O 调度算法会缓存尽可能多的 I/O 请求在 PageCache 中，最后「合并」成一个更大的 I/O请求再发给磁盘，这样做是为了减少磁盘的寻址操作；</li>
<li>内核也会「预读」后续的 I/O 请求放在 PageCache 中，一样是为了减少对磁盘的操作</li>
</ul>
<p>于是，传输大文件的时候，使用「异步 I/O + 直接 I/O」了，就可以无阻塞地读取文件了。</p>
<p>所以，传输文件的时候，我们要根据文件的大小来使用不同的方式：</p>
<ul>
<li>传输大文件的时候，使用「异步 I/O + 直接 I/O」；</li>
<li>传输小文件的时候，则使用「零拷贝技术」；</li>
</ul>
<p>在 nginx 中，我们可以用如下配置，来根据文件的大小来使用不同的方式：</p>
<pre><code class="language-nginx">location /video/ { 
    sendfile on; 
    aio on; 
    directio 1024m; 
}
</code></pre>
<p>当文件大小大于 <font color='red'>directio</font> 值后，使用「异步 I/O + 直接 I/O」，否则使用「零拷贝技术」。</p>
<h1 id="总结">总结</h1>
<p>早期 I/O 操作，内存与磁盘的数据传输的工作都是由 CPU 完成的，而此时 CPU 不能执行其他任务，会特别浪费 CPU 资源。</p>
<p>于是，为了解决这一问题，DMA 技术就出现了，每个 I/O 设备都有自己的 DMA 控制器，通过这个 DMA 控制器，CPU 只需要告诉 DMA 控制器，我们要传输什么数据，从哪里来，到哪里去，就可以放心离开了。后续的实际数据传输工作，都会由 DMA 控制器来完成，CPU 不需要参与数据传输的工作。</p>
<p>传统 IO 的工作方式，从硬盘读取数据，然后再通过网卡向外发送，我们需要进行 4 上下文切换，和 4 次数据拷贝，其中 2 次数据拷贝发生在内存里的缓冲区和对应的硬件设备之间，这个是由 DMA 完成，另外 2 次则发生在内核态和用户态之间，这个数据搬移工作是由 CPU 完成的。</p>
<p>为了提高文件传输的性能，于是就出现了零拷贝技术，它通过一次系统调用（sendfile 方法）合并了磁盘读取与网络发送两个操作，降低了上下文切换次数。另外，拷贝数据都是发生在内核中的，天然就降低了数据拷贝的次数。</p>
<p>Kafka 和 Nginx 都有实现零拷贝技术，这将大大提高文件传输的性能。</p>
<p>零拷贝技术是基于 PageCache 的，PageCache 会缓存最近访问的数据，提升了访问缓存数据的性能，同时，为了解决机械硬盘寻址慢的问题，它还协助 I/O 调度算法实现了 IO 合并与预读，这也是顺序读比随机读性能好的原因。这些优势，进一步提升了零拷贝的性能。</p>
<p>需要注意的是，零拷贝技术是不允许进程对文件内容作进一步的加工的，比如压缩数据再发送。</p>
<p>另外，当传输大文件时，不能使用零拷贝，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，并且大文件的缓存命中率不高，这时就需要使用「异步 IO + 直接 IO 」的方式。</p>
<p>在 Nginx 里，可以通过配置，设定一个文件大小阈值，针对大文件使用异步 IO 和直接 IO，而对小文件使用零拷贝。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[02.mysql的执行计划]]></title>
        <id>https://heshiyingx.github.io/post/02mysql-de-zhi-xing-ji-hua/</id>
        <link href="https://heshiyingx.github.io/post/02mysql-de-zhi-xing-ji-hua/">
        </link>
        <updated>2016-02-18T07:36:32.000Z</updated>
        <content type="html"><![CDATA[<h1 id="01执行计划的组成部分">01.执行计划的组成部分</h1>
<p>执行计划有id、select_type、table 、partitions、type、possible_keys、key 、key_len、ref 、rows、filtered、Extra组成。</p>
<h2 id="id">id</h2>
<p>执行计划的id标志</p>
<ul>
<li>单纯的join (没有子查询)id都是1且从上到下</li>
<li>Subquery,scala subquery都会使ID递增</li>
</ul>
<h2 id="select_type">select_type</h2>
<p>select类型</p>
<ul>
<li>SIMPLE:简单SELECT(不使用UNION或􏰂查询等)</li>
<li>primary:最外层的select,使用了union或者subquery的query并且不能被优化合并<pre><code>1.子查询中出现了limit就不能被优化合并。
</code></pre>
</li>
<li>union:UNION中的第二个或后面的SELECT语句(使用union结合的select除了第一个之外的select select_type用union)
<ul>
<li>union result是union去掉重复值的零时表</li>
<li>union all 不出现union result因为不去重</li>
</ul>
</li>
<li>subquery:子查询中的第一个SELECT</li>
<li>dependent subquery:􏰂查询中的第一个SELECT，依赖于外面的查询（UNION中的第二个或后面的SELECT语句，依赖于外面的查询）</li>
<li>derved:派生表的SELECT(FROM􏰂句的􏰂查询)
<ul>
<li>From后面表的位置上的subquery</li>
<li>Derived是生成在内存或者零时表空间中的</li>
<li>如果derived当做驱动表的时候要点是要减少数据量为目的</li>
<li>当作被驱动表的时候产生auto_key索引也是要以数据量为目的</li>
</ul>
</li>
<li>materialized:物化子查询
<ul>
<li>产生中间临时表(实体)</li>
<li>临时表自动创建索引并和其他表进行关联，提高性能</li>
<li>和子查询的区别是，优化器将可以进行 MATERIALIZED 的语句自动改写成 join ，并自动创建索引</li>
</ul>
</li>
<li>UNCACHEABLE SUBQUERY：不会被缓存的并且对于外部查询的每行都要重新计算的子查询</li>
<li>UNCACHEABLE UNION：属于不能被缓存的 UNION中的第二个或后面的SELECT语句</li>
</ul>
<h2 id="table">table</h2>
<p>输出记录的表</p>
<ul>
<li>通常是用户操作的用户表</li>
<li>&lt;unionM, N&gt; UNION得到的结果表</li>
<li>派生表，由id=N的语句产生</li>
<li>由子查询物化产生的表，由id=N的语句产生</li>
</ul>
<h2 id="partitions">partitions</h2>
<p>符合的分区</p>
<h2 id="type">type</h2>
<p>join的类型<br>
摘自姜老师的PDF，按照图上箭头的顺序来看，成本(cost)是从小到大<br>
<img src="https://heshiyingx.github.io/post-images/1613810532212.png" alt="" loading="lazy"></p>
<h2 id="possible_keys">possible_keys</h2>
<p>优化器可能使用到的索引</p>
<h2 id="key">key</h2>
<p>优化器实际使用的索引</p>
<h2 id="key_len">key_len</h2>
<p>使用索引的字节长度</p>
<h2 id="ref">ref</h2>
<p>进行比较的索引列。多用于被驱动表，显示驱动的字段。</p>
<h2 id="rows">rows</h2>
<p>优化器预估的扫描行</p>
<h2 id="filtered">filtered</h2>
<p>根据条件过滤得到的百分比</p>
<h2 id="extra">Extra</h2>
<p>额外的显示选项<br>
<strong>常见的extra</strong></p>
<table>
<thead>
<tr>
<th>常见值</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>Using filesort</td>
<td>需要使用额外的排序得到的结果</td>
</tr>
<tr>
<td>Using index</td>
<td>优化器只需要使用索引就能得到结果</td>
</tr>
<tr>
<td>Using index condition</td>
<td>优化器使用index condition pushdown优化</td>
</tr>
<tr>
<td>Using index for group by</td>
<td>优化器只需要使用索引就能处理group by 或distinct语句</td>
</tr>
<tr>
<td>Using join buffer</td>
<td>优化器需要使用join buffer,join_buffer_size</td>
</tr>
<tr>
<td>Using MRR</td>
<td>优化器使用MRR优化</td>
</tr>
<tr>
<td>Using temporary</td>
<td>优化器需要使用零时表</td>
</tr>
<tr>
<td>Using where</td>
<td>优化器使用where过滤</td>
</tr>
</tbody>
</table>
<ul>
<li>using filesort:可以使用复合索引将filesort优化。提高性能</li>
<li>using index:使用覆盖索引</li>
<li>using where:使用where过滤条件</li>
</ul>
<h1 id="02执行计划示例">02.执行计划示例</h1>
<pre><code class="language-sql">select * from employess as e ingore index(pri) straight_join t_group t on t.emp_no=e.emp_no;
</code></pre>
<p>执行计划：<br>
<img src="https://heshiyingx.github.io/post-images/1613652500897.png" alt="" loading="lazy"></p>
<h2 id="性能提升神器straight_join">【性能提升神器】STRAIGHT_JOIN</h2>
<pre><code>STRAIGHT_JOIN is similar to JOIN, except that the left table is always read before the right table. 
This can be used for those (few) cases for which the join optimizer puts the tables in the wrong order.
</code></pre>
<blockquote>
<blockquote>
<p>意思就是说STRAIGHT_JOIN功能同join类似，但能让左边的表来驱动右边的表，能改表优化器对于联表查询的执行顺序。</p>
</blockquote>
</blockquote>
<blockquote>
<blockquote>
<p>优化原理：在MySQL执行时会将驱动表的内容放到buffer_size中（内存）（mysql设置的参数为：join_buffer_size），所以性能提升。如果将数据量大的表当做驱动表而buffer_size存不下。那么就会使用磁盘存储，就到导致物理io，从而影响性能。同理，如果join_buffer_size足够大，任意表当做驱动表对性能无影响。</p>
</blockquote>
</blockquote>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[01.MySQL5.7配置文件]]></title>
        <id>https://heshiyingx.github.io/post/1mysql57-pei-zhi-wen-jian/</id>
        <link href="https://heshiyingx.github.io/post/1mysql57-pei-zhi-wen-jian/">
        </link>
        <updated>2016-02-06T06:50:44.000Z</updated>
        <content type="html"><![CDATA[<pre><code class="language-ini">[mysqld]
initialize-insecure # 关闭安全策略
# 服务端口号 默认3306
port = 3306 
user #用户
basedir # 指定mysql的安装目录
#mysql数据文件所在位置
datadir = /data/mysql1/data
#设置socke文件所在目录
socket  = /tmp/mysql.sock
# 监听的IP
bind-address = *
#指定默认时区，如果没有指定则和系统默认时区一致
default-time-zone = '+8:00'
# 默认5000，指定Mysqld运行过程中可以打开的文件数，避免出现” Too many open files”报错
 open-files-limit = 65535
# 指定Mysqld进程对应的程序ID文件，默认是在数据文件目录里
pid-file=/usr/local/mysql/data/M00006.pid
# 关闭自动更新一行数据中timestamp的数据
explicit_defaults_for_timestamp = on
# 打开安全更新，避免没有条件的update和delete
sql_safe_updates=1

########## mysqlx插件 ###############
mysqlx_port=33070
mysqlx_socket=/tmp/mysqlx33070.sock


#事务隔离级别，默认为可重复读，mysql默认可重复读级别（此级别下可能参数很多间隙锁，影响性能）
transaction_isolation = READ-COMMITTED
#数据库默认字符集,主流字符集支持一些特殊表情符号（特殊表情符占用4个字节）
character-set-server = utf8mb4
#数据库字符集对应一些排序等规则，注意要和character-set-server对应
collation-server = utf8mb4_general_ci
#设置client连接mysql时的字符集,防止乱码
init_connect='SET NAMES utf8mb4'
# mysql 5.7新增特性，磁盘临时表默认引擎，默认InnoDB
internal_tmp_disk_storage_engine = InnoDB
default-storage-engine = InnoDB
#是否对sql语句大小写敏感，1表示不敏感
lower_case_table_names = 1

############日志设置#########
#数据库错误日志文件
log_error =/data/mysql1/log/web01_error.log
#一般日志
general_log_file =/data/mysql1/log/web01_general.log
#是否开启一般日志
general_log = 0
# 记录没有使用索引的查询
log_queries_not_using_indexes =1
#慢查询sql日志设置
slow_query_log = 1
slow_query_log_file = /data/mysql1/log/web01_slow.log
# 关闭查询缓存
query-cache-type = 0 
binlog_format=row #记录日志的格式
binlog_row_image=full #会记录数据更改前后的结果

############## 组提交 ###############
# 在并发不高的时候不开，否则，可能造成等待
binlog_group_commit_sync_delay=20 #mysql最迟多久提交一次
binlog_group_commit_sync_no_delay_count=1000 #mysql最多提交事务的个数

#############主从(从)#################
skip_slave_start=1 #该选项能够阻止备库在崩溃后自动启动复制，崩溃后启动复制，数据可能不一致
log_slave_updates=1    #允许备库将其重放的事件也记录到自身的二进制日志中。
read_only = 1   #该选项会阻止任何没有特权权限的线程修改数据。


# 指定索引缓冲区的大小，它决定索引处理的速度，尤其是索引读的速度。
#一般不适用myslam引擎范围是8~32M，足够了，
#如果使用，通过检查状态值Key_read_requests和Key_reads，可以知道key_buffer_size设置是否合理。比例key_reads /key_read_requests应该尽可能的低，至少是1:100，1:1000更好（上述状态值可以使用SHOW STATUS LIKE ‘key_read%'获得）
key_buffer_size = 32M

# 一般设置成物理内存的50~70%
# 数据缓存--InnoDB数据页面
# 索引缓存--索引数据
# 缓冲数据--脏页（在内存中修改尚未刷新(写入)到磁盘的数据）
# 内部结构--如自适应哈希索引，行锁等。通过命中概率，可以了解，ibp是否足够
innodb_buffer_pool_size = 2867M


innodb_buffer_pool_instances = 4
innodb_buffer_pool_load_at_startup = 1
innodb_buffer_pool_dump_at_shutdown = 1
# 根据您的服务器IOPS能力适当调整
# 一般配普通SSD盘的话，可以调整到 10000 - 20000
# 配置高端PCIe SSD卡的话，则可以调整的更高，比如 50000 - 80000
innodb_io_capacity = 4000
# 并发线程数，0为不限制
innodb_thread_concurrency = 0
# 慢查询的时间超过50ms的即是慢查询，开发环境建议是0.01
long_query_time = 0.05
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[01.supervisor的使用]]></title>
        <id>https://heshiyingx.github.io/post/01supervisor-de-shi-yong/</id>
        <link href="https://heshiyingx.github.io/post/01supervisor-de-shi-yong/">
        </link>
        <updated>2016-02-03T15:37:17.000Z</updated>
        <content type="html"><![CDATA[<h1 id="1为什么要使用supervisor">1.为什么要使用supervisor</h1>
<p>在维护Linux服务中，有很多程序是没有启动脚本的，并且还是前台运行进程占用着shell窗口，窗口关闭程序也就随之关闭。比如flask和Django的启动程序。如果需要放在后台运行，并且能方便的重启，关闭，该怎么办呢？</p>
<p>我们supervisor去管理这些进程。supervisor提供了如下功能。</p>
<ul>
<li>将前台进程转换为后台进程。</li>
<li>能监控进程的运行状态，如进程的异常退出，supervisor则会自动重启进程。</li>
<li>能对服务方便快捷的进行启动、重启、关闭等便捷操作。</li>
<li>提供了web ui界面，便于直接使用。</li>
</ul>
<h1 id="2supervisor的基础组件">2.Supervisor的基础组件</h1>
<ul>
<li>
<p>supervisord</p>
<p>supervisor的主进程，负责管理被管理进程的服务。并且监控其他被管理进程的状态，对于crash的进程会自动重启</p>
</li>
<li>
<p>supervisorctl</p>
<p>是supervisor的命令行管理工具，可以通过supervisorctl查看被管理进程的状态以及启动，重启，关闭等操作。supervisorctl和其他很多命令行工具一样（如redis-cli）既可以连接本地的supervisor也可以连接远程的supervisor。</p>
</li>
<li>
<p>web server</p>
<p>supervisor提供了一个web服务的页面，可以方便的在页面进行操作。</p>
</li>
<li>
<p>xml-rpc interface</p>
<p>supervisor的通讯协议。</p>
</li>
</ul>
<h1 id="3supervisor的安装">3.supervisor的安装</h1>
<pre><code class="language-bash">yum install epel-release -y &amp;&amp; # 安装epel源
yum install supervisor -y # 安装supervisor
</code></pre>
<p><strong>启动</strong></p>
<pre><code class="language-bash">systemctl enable supervisord # 加入开机自动启动
systemctl start supervisord # 启动supervisor
</code></pre>
<h1 id="4supervisor的配置解读">4.supervisor的配置解读</h1>
<p>配置文件路径：/etc/supervisord.conf</p>
<ul>
<li>
<p>unix_http_server (supervisor的unix管理服务配置)</p>
<pre><code class="language-ini">[unix_http_server]
file=/var/run/supervisor/supervisor.sock   ; (the path to the socket file)
;chmod=0700                 ; sockef file mode (default 0700)
;chown=nobody:nogroup       ; socket file uid:gid owner
;username=user              ; (default is no username (open server))
;password=123               ; (default is no password (open server))
</code></pre>
</li>
<li>
<p>inet_http_server(supervisor的web服务配置)</p>
<pre><code class="language-ini">;[inet_http_server]         ; inet (TCP) server disabled by default
;port=127.0.0.1:9001        ; (ip_address:port specifier, *:port for all iface)
;username=user              ; (default is no username (open server))
;password=123               ; (default is no password (open server))
</code></pre>
</li>
<li>
<p>supervisord （supervisor主进程的配置）</p>
<pre><code class="language-ini">[supervisord]
logfile=/var/log/supervisor/supervisord.log  ; (main log file;default $CWD/supervisord.log)
logfile_maxbytes=50MB       ; (max main logfile bytes b4 rotation;default 50MB)
logfile_backups=10          ; (num of main logfile rotation backups;default 10)
loglevel=info               ; (log level;default info; others: debug,warn,trace)
pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)
nodaemon=false              ; (start in foreground if true;default false)
minfds=1024                 ; (min. avail startup file descriptors;default 1024)
minprocs=200                ; (min. avail process descriptors;default 200)
;umask=022                  ; (process file creation umask;default 022)
;user=chrism                 ; (default is current user, required if root)
;identifier=supervisor       ; (supervisord identifier, default is 'supervisor')
;directory=/tmp              ; (default is not to cd during start)
;nocleanup=true              ; (don't clean up tempfiles at start;default false)
;childlogdir=/tmp            ; ('AUTO' child log dir, default $TEMP)
;environment=KEY=value       ; (key value pairs to add to environment)
;strip_ansi=false            ; (strip ansi escape codes in logs; def. false)
</code></pre>
</li>
<li>
<p>supervisorctl(supervisor命令行工具的配置)</p>
<pre><code class="language-ini">[supervisorctl]
serverurl=unix:///var/run/supervisor/supervisor.sock ; use a unix:// URL  for a unix socket
;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket
;username=chris              ; should be same as http_username if set
;password=123                ; should be same as http_password if set
;prompt=mysupervisor         ; cmd line prompt (default &quot;supervisor&quot;)
;history_file=~/.sc_history  ; use readline history if available
</code></pre>
</li>
<li>
<p>program:theprogramname（定义要管理的进程的配置）</p>
<pre><code class="language-ini">;[program:theprogramname]
;command=/bin/cat              ; the program (relative uses PATH, can take args)
;process_name=%(program_name)s ; process_name expr (default %(program_name)s)
;numprocs=1                    ; number of processes copies to start (def 1)
;directory=/tmp                ; directory to cwd to before exec (def no cwd)
;umask=022                     ; umask for process (default None)
;priority=999                  ; the relative start priority (default 999)优先级低则先启动，后关闭
;autostart=true                ; start at supervisord start (default: true)启动supervisord的服务后自动拉起该进程
;autorestart=true              ; retstart at unexpected quit (default: true)异常自动重启
;startsecs=10                  ; number of secs prog must stay running (def. 1)启动后多少秒存活才被认为running状态
;startretries=3                ; max # of serial start failures (default 3)
;exitcodes=0,2                 ; 'expected' exit codes for process (default 0,2)
;stopsignal=QUIT               ; signal used to kill process (default TERM)
;stopwaitsecs=10               ; max num secs to wait b4 SIGKILL (default 10)
;user=chrism                   ; setuid to this UNIX account to run the program
;redirect_stderr=true          ; redirect proc stderr to stdout (default false)
;stdout_logfile=/a/path        ; stdout log path, NONE for none; default AUTO
;stdout_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;stdout_logfile_backups=10     ; # of stdout logfile backups (default 10)
;stdout_capture_maxbytes=1MB   ; number of bytes in 'capturemode' (default 0)
;stdout_events_enabled=false   ; emit events on stdout writes (default false)
;stderr_logfile=/a/path        ; stderr log path, NONE for none; default AUTO
;stderr_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;stderr_logfile_backups=10     ; # of stderr logfile backups (default 10)
;stderr_capture_maxbytes=1MB   ; number of bytes in 'capturemode' (default 0)
;stderr_events_enabled=false   ; emit events on stderr writes (default false)
;environment=A=1,B=2           ; process environment additions (def no adds)
;serverurl=AUTO                ; override serverurl computation (childutils)
</code></pre>
</li>
<li>
<p>group:thegroupname(将被管理的进程分组)</p>
<pre><code class="language-ini">;[group:thegroupname]
;programs=progname1,progname2  ; each refers to 'x' in [program:x] definitions
;priority=999                  ; the relative start priority (default 999)

; The [include] section can just contain the &quot;files&quot; setting.  This
; setting can list multiple files (separated by whitespace or
; newlines).  It can also contain wildcards.  The filenames are
; interpreted as relative to this file.  Included files *cannot*
; include files themselves.
</code></pre>
</li>
<li>
<p>include(被管理进程配置文件的目录)</p>
<pre><code class="language-ini">[include]
files = supervisord.d/*.ini
</code></pre>
</li>
</ul>
<h1 id="5supervisor示例">5.supervisor示例</h1>
<h2 id="51supervisor管理python项目">5.1.supervisor管理Python项目</h2>
<ul>
<li>1.创建Django工程</li>
</ul>
<pre><code class="language-bash">yum install openssl-devel bzip2-devel expat-devel gdbm-devel readline-devel sqlite-devel gcc gcc-c++ openssl-devel zlib zlib-devel python3 python3-devel -y #安装组件依赖包

pip3 install -i https://mirrors.aliyun.com/pypi/simple/ --upgrade pip # 升级pip
pip3 install -i https://mirrors.aliyun.com/pypi/simple/ django==2.1.8 # 安装Django
django-admin startproject demosite #新建Django工程
cd demosite
python3 manage.py runserver 0.0.0.0:8002
</code></pre>
<ul>
<li>2.创建supervisor的管理进程配置文件</li>
</ul>
<pre><code class="language-ini"># vim /etc/supervisord.d/demosite.ini
[program:demosite]
command=/bin/bash -c &quot;python3  manage.py runserver 0.0.0.0:8002&quot;         ; the program (relative uses PATH, can take args)
;;process_name=%(program_name)s ; process_name expr (default %(program_name)s)
;;numprocs=1                    ; number of processes copies to start (def 1)
directory=/root/demosite                ; directory to cwd to before exec (def no cwd)
;;umask=022                     ; umask for process (default None)
;;priority=999                  ; the relative start priority (default 999)优先级低则先启动，后关闭
autostart=true                ; start at supervisord start (default: true)启动supervisord的服务后自动拉起该进程
autorestart=true              ; retstart at unexpected quit (default: true)异常自动重启
startsecs=10                  ; number of secs prog must stay running (d
;;stopsignal=QUIT               ; signal used to kill process (default TERM)
;;stopwaitsecs=10               ; max num secs to wait b4 SIGKILL (default 10)
user=root                   ; setuid to this UNIX account to run the program
;;redirect_stderr=true          ; redirect proc stderr to stdout (default false)
stdout_logfile=/root/demosite/logs/std_log.log        ; stdout log path, NONE for none; default AUTO
;;stdout_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;;stdout_logfile_backups=10     ; # of stdout logfile backups (default 10)
;;stdout_capture_maxbytes=1MB   ; number of bytes in 'capturemode' (default 0)
;;stdout_events_enabled=false   ; emit events on stdout writes (default false)
stderr_logfile=/root/demosite/logs/err_log.log        ; stderr log path, NONE for none; default AUTO
stopasgroup=true ;如果supervisor停止，则该进程也stop，避免成为孤儿进程
killasgroup=true
;;stderr_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB)
;;stderr_logfile_backups=10     ; # of stderr logfile backups (default 10)
;;stderr_capture_maxbytes=1MB   ; number of bytes in 'capturemode' (default 0)
;;stderr_events_enabled=false   ; emit events on stderr writes (default false)
</code></pre>
<h1 id="6supervisorctl常用命令">6.supervisorctl常用命令</h1>
<pre><code class="language-bash">supervisorctl status        //查看所有进程的状态
supervisorctl stop es       //停止es
supervisorctl start es      //启动es
supervisorctl restart       //重启es
supervisorctl update        //配置文件修改后使用该命令加载新的配置
supervisorctl reload        //重新启动配置中的所有程序
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Hello Gridea]]></title>
        <id>https://heshiyingx.github.io/post/hello-gridea/</id>
        <link href="https://heshiyingx.github.io/post/hello-gridea/">
        </link>
        <updated>2016-02-01T12:02:06.000Z</updated>
        <summary type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
]]></summary>
        <content type="html"><![CDATA[<p>👏  欢迎使用 <strong>Gridea</strong> ！<br>
✍️  <strong>Gridea</strong> 一个静态博客写作客户端。你可以用它来记录你的生活、心情、知识、笔记、创意... ...</p>
<!-- more -->
<p><a href="https://github.com/getgridea/gridea">Github</a><br>
<a href="https://gridea.dev/">Gridea 主页</a><br>
<a href="http://fehey.com/">示例网站</a></p>
<h2 id="特性">特性👇</h2>
<p>📝  你可以使用最酷的 <strong>Markdown</strong> 语法，进行快速创作</p>
<p>🌉  你可以给文章配上精美的封面图和在文章任意位置插入图片</p>
<p>🏷️  你可以对文章进行标签分组</p>
<p>📋  你可以自定义菜单，甚至可以创建外部链接菜单</p>
<p>💻  你可以在 <strong>Windows</strong>，<strong>MacOS</strong> 或 <strong>Linux</strong> 设备上使用此客户端</p>
<p>🌎  你可以使用 <strong>𝖦𝗂𝗍𝗁𝗎𝖻 𝖯𝖺𝗀𝖾𝗌</strong> 或 <strong>Coding Pages</strong> 向世界展示，未来将支持更多平台</p>
<p>💬  你可以进行简单的配置，接入 <a href="https://github.com/gitalk/gitalk">Gitalk</a> 或 <a href="https://github.com/SukkaW/DisqusJS">DisqusJS</a> 评论系统</p>
<p>🇬🇧  你可以使用<strong>中文简体</strong>或<strong>英语</strong></p>
<p>🌁  你可以任意使用应用内默认主题或任意第三方主题，强大的主题自定义能力</p>
<p>🖥  你可以自定义源文件夹，利用 OneDrive、百度网盘、iCloud、Dropbox 等进行多设备同步</p>
<p>🌱 当然 <strong>Gridea</strong> 还很年轻，有很多不足，但请相信，它会不停向前 🏃</p>
<p>未来，它一定会成为你离不开的伙伴</p>
<p>尽情发挥你的才华吧！</p>
<p>😘 Enjoy~</p>
]]></content>
    </entry>
</feed>